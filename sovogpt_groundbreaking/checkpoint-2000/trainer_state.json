{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 8.695652173913043,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 5.94190788269043,
      "learning_rate": 2.9966415771991526e-05,
      "loss": 5.7303,
      "step": 50
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 2.048100233078003,
      "learning_rate": 2.9863065197694013e-05,
      "loss": 1.9665,
      "step": 100
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 1.6672767400741577,
      "learning_rate": 2.9690416152372723e-05,
      "loss": 1.2793,
      "step": 150
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 2.54778790473938,
      "learning_rate": 2.944927360557501e-05,
      "loss": 1.0467,
      "step": 200
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 1.3965985774993896,
      "learning_rate": 2.914076187517001e-05,
      "loss": 0.9747,
      "step": 250
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 1.5771920680999756,
      "learning_rate": 2.8766319385259717e-05,
      "loss": 0.8252,
      "step": 300
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 1.9449557065963745,
      "learning_rate": 2.8327691959581835e-05,
      "loss": 0.8462,
      "step": 350
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 1.4786499738693237,
      "learning_rate": 2.782692468167359e-05,
      "loss": 0.8163,
      "step": 400
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 1.4795101881027222,
      "learning_rate": 2.7266352359748248e-05,
      "loss": 0.7296,
      "step": 450
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 1.1561897993087769,
      "learning_rate": 2.664858864074141e-05,
      "loss": 0.6753,
      "step": 500
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 1.4645384550094604,
      "learning_rate": 2.5976513824282506e-05,
      "loss": 0.6938,
      "step": 550
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 1.2437195777893066,
      "learning_rate": 2.5253261433408325e-05,
      "loss": 0.6736,
      "step": 600
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 1.178841233253479,
      "learning_rate": 2.448220360463211e-05,
      "loss": 0.6807,
      "step": 650
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 0.8888246417045593,
      "learning_rate": 2.3666935365486498e-05,
      "loss": 0.6606,
      "step": 700
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 1.8616127967834473,
      "learning_rate": 2.281125787284563e-05,
      "loss": 0.6564,
      "step": 750
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 1.4752352237701416,
      "learning_rate": 2.1919160690177115e-05,
      "loss": 0.6286,
      "step": 800
    },
    {
      "epoch": 3.6956521739130435,
      "grad_norm": 1.0474380254745483,
      "learning_rate": 2.09948031863555e-05,
      "loss": 0.5532,
      "step": 850
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 1.0296131372451782,
      "learning_rate": 2.0042495142764516e-05,
      "loss": 0.5927,
      "step": 900
    },
    {
      "epoch": 4.130434782608695,
      "grad_norm": 1.5706888437271118,
      "learning_rate": 1.9066676659106795e-05,
      "loss": 0.585,
      "step": 950
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 1.2627644538879395,
      "learning_rate": 1.807189745160942e-05,
      "loss": 0.5385,
      "step": 1000
    },
    {
      "epoch": 4.565217391304348,
      "grad_norm": 1.469531774520874,
      "learning_rate": 1.706279564014666e-05,
      "loss": 0.5295,
      "step": 1050
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 1.3250840902328491,
      "learning_rate": 1.6044076123184034e-05,
      "loss": 0.5478,
      "step": 1100
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0718461275100708,
      "learning_rate": 1.502048864136983e-05,
      "loss": 0.5629,
      "step": 1150
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 0.7298890352249146,
      "learning_rate": 1.3996805632051613e-05,
      "loss": 0.4808,
      "step": 1200
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 1.2535589933395386,
      "learning_rate": 1.2977799977970275e-05,
      "loss": 0.5103,
      "step": 1250
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 1.1482616662979126,
      "learning_rate": 1.1968222753877428e-05,
      "loss": 0.5147,
      "step": 1300
    },
    {
      "epoch": 5.869565217391305,
      "grad_norm": 1.256664514541626,
      "learning_rate": 1.0972781074831753e-05,
      "loss": 0.5032,
      "step": 1350
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 1.2231534719467163,
      "learning_rate": 9.996116149455668e-06,
      "loss": 0.4405,
      "step": 1400
    },
    {
      "epoch": 6.304347826086957,
      "grad_norm": 1.0002120733261108,
      "learning_rate": 9.042781640478292e-06,
      "loss": 0.467,
      "step": 1450
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 1.2619863748550415,
      "learning_rate": 8.117222433457717e-06,
      "loss": 0.4458,
      "step": 1500
    },
    {
      "epoch": 6.739130434782608,
      "grad_norm": 1.0493133068084717,
      "learning_rate": 7.223753912672723e-06,
      "loss": 0.4756,
      "step": 1550
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 1.1981455087661743,
      "learning_rate": 6.3665418408091775e-06,
      "loss": 0.4561,
      "step": 1600
    },
    {
      "epoch": 7.173913043478261,
      "grad_norm": 1.09159255027771,
      "learning_rate": 5.549582936251428e-06,
      "loss": 0.4367,
      "step": 1650
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 1.3237910270690918,
      "learning_rate": 4.776686238536206e-06,
      "loss": 0.4461,
      "step": 1700
    },
    {
      "epoch": 7.608695652173913,
      "grad_norm": 0.621722936630249,
      "learning_rate": 4.051455348852001e-06,
      "loss": 0.4356,
      "step": 1750
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 1.1368831396102905,
      "learning_rate": 3.3772716283868275e-06,
      "loss": 0.391,
      "step": 1800
    },
    {
      "epoch": 8.043478260869565,
      "grad_norm": 0.6868089437484741,
      "learning_rate": 2.7572784328614464e-06,
      "loss": 0.4188,
      "step": 1850
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 0.9248381853103638,
      "learning_rate": 2.1943664567539965e-06,
      "loss": 0.4054,
      "step": 1900
    },
    {
      "epoch": 8.478260869565217,
      "grad_norm": 1.0146806240081787,
      "learning_rate": 1.6911602555479038e-06,
      "loss": 0.3998,
      "step": 1950
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 1.041267991065979,
      "learning_rate": 1.250006008842699e-06,
      "loss": 0.4318,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 2300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2389218399092736.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
